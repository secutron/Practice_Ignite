{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A.1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMYpC16BF5DFBRwqk1ssy0O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6457b4c36807480f9ee9c020640ee2d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7854623a62584e958127ff020ce55ed9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a24a44f25e6e454d8c986d45242581cf",
              "IPY_MODEL_ae38e46c9fec48c89135f7c2a8b55de2",
              "IPY_MODEL_6041bf971e564762aa5235efcd86212f"
            ]
          }
        },
        "7854623a62584e958127ff020ce55ed9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a24a44f25e6e454d8c986d45242581cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_11afaea95b25462dba27f80cbb1f2beb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d55271f163c24a3bb88b0bd336960722"
          }
        },
        "ae38e46c9fec48c89135f7c2a8b55de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e238024fe5584031b78cad9238c4c4b4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_964b446e8c5742c88f9a0b14337ec7c8"
          }
        },
        "6041bf971e564762aa5235efcd86212f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cbf4006615474038bb92d8dfde17e533",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:02&lt;00:00, 56922590.16it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1cafb7ab72c74fdc8ee36d846c37e060"
          }
        },
        "11afaea95b25462dba27f80cbb1f2beb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d55271f163c24a3bb88b0bd336960722": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e238024fe5584031b78cad9238c4c4b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "964b446e8c5742c88f9a0b14337ec7c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cbf4006615474038bb92d8dfde17e533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1cafb7ab72c74fdc8ee36d846c37e060": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/secutron/Practice_Ignite/blob/main/A_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfVeNJIVYVu9"
      },
      "source": [
        "## Resnet18 + CIFAR10 on CPU/TPU/GPU using 'ignite'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK6Pe16EpvP3"
      },
      "source": [
        "##A.1. 속성 예제 \n",
        "\n",
        " 때로는 역순으로, 완결 코드로부터 시작하여 궁금한 부분만 선택적으로 확인하는 것이 더 효율적일 때가 있다. 이를 위해 이그나이트([ignite](https://pytorch.org/ignite/))의 auto_dataloader와 auto_model, auto_optim, 그리고 트레이너(trainer)와 이벤트 핸들러(event handler)등의 중요한 부분을  포함하는, 구글 colab 기반의 속성 예제 코드를 아래와 같이 준비하였다.\n",
        "\n",
        " 그리고 이그나이트([ignite](https://pytorch.org/ignite/))는 작성 시점을 기준으로 다음의 백엔드들을 지원한다.\n",
        "\n",
        "- backends from native torch distributed configuration: “nccl”, “gloo”, “mpi”\n",
        "- XLA on TPUs via pytorch/xla\n",
        "- using Horovod framework as a backend\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT0sitfdvGKS"
      },
      "source": [
        "###A.1.1. Colab runtime 설정\n",
        "\n",
        " 분산처리에 익숙하지 않은 개발자의 경우, 구글 colab을 이용하여 DDL(Distributed Deep Learning)의 기초를 연습하는 것이 여러 면에서 장점이 있다. 우선 가장 중요한 것은 CPU와 GPU, 그리고 TPU 환경을 쉽게 번갈아가며 분산처리 코드의 동작 상태를 확인할 수 있다는 점이다. ~~그리고 colab은 무료이다. 럭셔리한 환경이라면 GCP를 사용해도 좋겠지.~~ \n",
        "\n",
        " 다만 아쉽게도 현 시점에서 colab 무료 버전을 사용하는 경우, 멀티 GPU(Multi-GPU)나 멀티 노드 (Multi-Node)환경은 테스트할 수 없다. 하지만 이그나이트([ignite](https://pytorch.org/ignite/))에서는 작성한 단일 코드를 다양한 환경에서 동일하게 사용할 수 있으므로, 가능한 편안한 환경에서 코드 개발을 선행하고 이후 멀티노드와 같은 목표 환경으로 옮기는 작업 방식을 추천한다. \n",
        "\n",
        "  Colab에서는 아래 그림에서와 같이 런타임 환경 설정을 통해 CPU와 GPU, TPU 사용을 선택할 수 있다. ~~하드웨어 가속기가 None이면 CPU만 사용한다는 뜻~~\n",
        "\n",
        " <div align=\"center\">\n",
        "<img width=512 src=\"https://i.imgur.com/gcm9MlH.png\"/>\n",
        "</div>\n",
        "\n",
        " 런타임 변경이 발생할 때마다 새로운 VM(Virtual Machine)이 할당되며, 기존 노트 셀(cell)을  실행시킨 내용이 모두 사라지게 되므로 이에 주의한다. 코드 수정이 사라지는  것이 아니라 셀 실행한 내용이 사라지게 되는 것이다. 예를 들어 셀 실행을 통해 학습 데이터를 VM에 내려받은 경우, 런타임 변경을 통해 새롭게 VM이 할당될 경우 기존 내려받은 데이터는 당연히 새로운 VM에서 찾아볼 수 없다.\n",
        "\n",
        "  그리고 TPU를 통해 분산처리를 진행하는 경우, 특별히 colab runtime을 TPU 구동이 가능한 VM으로 환경을 설정해주는 작업이  필요하다. 이를 위해 아래와 같은 코드로 colab의 runtime type이 TPU인지 먼저 확인한다. 그리고 검출된 환경이 TPU인 경우, 분산처리가 가능한 런타임으로 변경하는 작업을 수행한다. 참고로 GPU 사용 시에는 런타임 유형 변경에서 GPU를 선택하는 것만으로 GPU를 사용할 수 있다. \n",
        "\n",
        " 다행히 파이토치 커뮤니티에서는 아래와 같이 사용이 편리한 xla 설정 관련 스크립트를 제공하고 있다. \n",
        "\n",
        " ** 가이드라인 작성 시점 기준 잔여 issue로, 20210304 version으로 지정함\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdhoeHGgsimM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49309958-ff9a-4f03-a472-f8ee62b262a4"
      },
      "source": [
        "import os\n",
        "\n",
        "gpu_gtg = False\n",
        "if int(os.environ.get(\"COLAB_GPU\")) > 0:\n",
        "    gpu_gtg = \"COLAB_GPU\" in os.environ\n",
        "\n",
        "tpu_gtg = \"COLAB_TPU_ADDR\" in os.environ\n",
        "\n",
        "if tpu_gtg: # tpu\n",
        "    print(\"TPU\")\n",
        "    #VERSION = \"nightly\"\n",
        "\n",
        "    # https://github.com/pytorch/builder/pull/750\n",
        "    VERSION = \"20210304\" # was 20200607\" \n",
        "\n",
        "    !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "    !python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TPU\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  5116  100  5116    0     0  29572      0 --:--:-- --:--:-- --:--:-- 29572\n",
            "Updating... This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-dev20210304 ...\n",
            "Found existing installation: torch 1.9.0+cu102\n",
            "Collecting cloud-tpu-client\n",
            "  Downloading cloud_tpu_client-0.10-py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client) (4.1.3)\n",
            "Collecting google-api-python-client==1.8.0\n",
            "  Downloading google_api_python_client-1.8.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.34.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.0.4)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.15.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (3.0.1)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.26.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (57.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.53.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.17.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (21.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2018.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (0.2.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.10)\n",
            "Uninstalling torch-1.9.0+cu102:\n",
            "Installing collected packages: google-api-python-client, cloud-tpu-client\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 1.12.8\n",
            "    Uninstalling google-api-python-client-1.12.8:\n",
            "      Successfully uninstalled google-api-python-client-1.12.8\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "earthengine-api 0.1.278 requires google-api-python-client<2,>=1.12.1, but you have google-api-python-client 1.8.0 which is incompatible.\u001b[0m\n",
            "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0\n",
            "  Successfully uninstalled torch-1.9.0+cu102\n",
            "Found existing installation: torchvision 0.10.0+cu102\n",
            "Uninstalling torchvision-0.10.0+cu102:\n",
            "  Successfully uninstalled torchvision-0.10.0+cu102\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20210304-cp37-cp37m-linux_x86_64.whl...\n",
            "Done updating TPU runtime\n",
            "\\ [1 files][126.5 MiB/126.5 MiB]                                                \n",
            "Operation completed over 1 objects/126.5 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20210304-cp37-cp37m-linux_x86_64.whl...\n",
            "\\ [1 files][138.1 MiB/138.1 MiB]                                                \n",
            "Operation completed over 1 objects/138.1 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20210304-cp37-cp37m-linux_x86_64.whl...\n",
            "/ [1 files][  4.6 MiB/  4.6 MiB]                                                \n",
            "Operation completed over 1 objects/4.6 MiB.                                      \n",
            "Processing ./torch-nightly+20210304-cp37-cp37m-linux_x86_64.whl\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==nightly+20210304) (3.7.4.3)\n",
            "Installing collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 1.0.61 requires torchvision, which is not installed.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.9.0a0+gitc4c77e2 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0a0+gitc4c77e2\n",
            "Processing ./torch_xla-nightly+20210304-cp37-cp37m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "Successfully installed torch-xla-1.9+e6237f2\n",
            "Processing ./torchvision-nightly+20210304-cp37-cp37m-linux_x86_64.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchvision==nightly+20210304) (1.9.0a0+gitc4c77e2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==nightly+20210304) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==nightly+20210304) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchvision==nightly+20210304) (3.7.4.3)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.9.0a0+7d41547\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libomp5\n",
            "0 upgraded, 1 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 234 kB of archives.\n",
            "After this operation, 774 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Fetched 234 kB in 1s (343 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 148492 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNby47f71vRB"
      },
      "source": [
        " 다음과 같이 이그나이트의 최신 version을 설치한다. 현 시점 기준 Colab에서 제공하는 VM은, 이그나이트가 사전 설치되어 있지 않은 상태이기 때문이다.  ~~참고로 pip 명령어는 package installer for python)의 약자이며, 아래 명령문 실행 시 이그나이트의 pre-release를 PyPI(python package index)로부터 설치하게 된다.~~\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27ND-qg2tJEU",
        "outputId": "1c95ba5a-6fb2-43d0-809b-eac6c058cdb1"
      },
      "source": [
        "!pip install --pre pytorch-ignite"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.5.0.dev20210913-py3-none-any.whl (233 kB)\n",
            "\u001b[K     |████████████████████████████████| 233 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.9.0a0+gitc4c77e2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.5.0.dev20210913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5OggR1m2NTU"
      },
      "source": [
        "상기 결과에 따르면, 본 가이드라인 작성 시점의 최신 버전인 xxxx년 x월 xx일자 (예: 2021년 9월 10일자) 이그나이트 x.x.x (예: 0.5.0)가 설치 되었음을 알 수 있다.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlmKaoMc2PEs"
      },
      "source": [
        "이제 필요한 환경이 적절히 준비되었으므로, 필요한 패키지를 아래 코드에서와 같이 로드한다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYoQTy8JtJBU"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, models\n",
        "\n",
        "import torchsummary\n",
        "\n",
        "import ignite\n",
        "import ignite.distributed as idist\n",
        "from ignite.engine import Engine, Events, create_supervised_evaluator, create_supervised_trainer\n",
        "from ignite.metrics import Accuracy, Loss, RunningAverage, ConfusionMatrix\n",
        "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
        "from ignite.utils import setup_logger"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0bZaFYCggop"
      },
      "source": [
        " 그리고 병렬 처리될 training 함수 내에서 파이토치 사용 시와 동일하게 dataloader 처리를 진행한다. 이그나이트는 파이토치 기반의 wrapper이며, dataloader나 모델 architecturing 등은 기존 파이토치의 모델 학습 시의 pipeline 을 그대로 이용한다. 따라서 파이토치에 익숙하지 않을 경우 가이드라인 이해가 어려울 수 있음을 서문에서 언급한 바 있다.\n",
        "\n",
        " 그 외 이그나이트에서 지원하는 auto_dataloader와 auto_model, auto_optim, 그리고 트레이너(trainer)와 이벤트 핸들러(event handler) 등의 중요한 부분을 아래와 같이 구현한다. 일반적인 지도학습(supervised learning)의 경우 이그나이트를 이용해 매우 간단하게 구현할 수 있음을 확인할 수 있다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va-GVsDLyijz"
      },
      "source": [
        "def training(local_rank, config, **kwargs):\n",
        "    print(\"local rank: \", local_rank)\n",
        "\n",
        "    ###########################################################\n",
        "    # 데이터 준비\n",
        "    train_transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Pad(4),\n",
        "            transforms.RandomCrop(32, fill=128),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    test_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),])\n",
        "\n",
        "    if idist.get_local_rank() > 0:\n",
        "        idist.barrier()\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root=config[\"data_path\"], train=True, download=True, transform=train_transform)\n",
        "    testset = torchvision.datasets.CIFAR10(root=config[\"data_path\"], train=False, download=True, transform=test_transform)\n",
        "\n",
        "    if idist.get_local_rank() == 0:\n",
        "        idist.barrier()\n",
        "\n",
        "    trainloader = idist.auto_dataloader(trainset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=config[\"num_workers\"], drop_last=True)\n",
        "    testloader = idist.auto_dataloader(testset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=config[\"num_workers\"],)\n",
        "\n",
        "\n",
        "    ###########################################################\n",
        "    # 모델, 옵티마이저, 로스, 트레이너, 이밸류에이터\n",
        "    num_classes = 10\n",
        "    model = models.resnet18(num_classes = num_classes)\n",
        "       \n",
        "    model = idist.auto_model(model)\n",
        "    optimizer = idist.auto_optim(optim.Adam(model.parameters(), lr=0.001))\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss().to(idist.device())\n",
        "\n",
        "    trainer = create_supervised_trainer(model, optimizer, criterion, device=idist.device())\n",
        "    trainer.logger = setup_logger(\"hkim-trainer\")\n",
        "\n",
        "    metrics = {\n",
        "        'accuracy':Accuracy(),\n",
        "        'ce':Loss(criterion),\n",
        "        'cm':ConfusionMatrix(num_classes=num_classes)\n",
        "    }\n",
        "\n",
        "    train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=idist.device())\n",
        "    train_evaluator.logger = setup_logger(\"hkim-train_evaluator\")\n",
        "\n",
        "    val_evaluator = create_supervised_evaluator(model, metrics=metrics, device=idist.device())\n",
        "    val_evaluator.logger = setup_logger(\"hkim-val_evaluator\")\n",
        "\n",
        "\n",
        "    # track a running average of the scalar loss output for each batch.\n",
        "    RunningAverage(output_transform=lambda x: x).attach(trainer, 'loss')\n",
        "\n",
        "    ###########################################################\n",
        "    # 이벤트\n",
        "    @trainer.on(Events.EPOCH_COMPLETED)\n",
        "    def log_training_results(trainer):\n",
        "        state = train_evaluator.run(trainloader)\n",
        "        metrics = train_evaluator.state.metrics\n",
        "        accuracy = metrics['accuracy']*100\n",
        "        loss = metrics['ce']\n",
        "        log_metrics(train_evaluator.logger, state.epoch, state.times[\"COMPLETED\"], \"train evaluator\", state.metrics)\n",
        "        #print(\"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
        "        #    .format(trainer.state.epoch, accuracy, loss))\n",
        "\n",
        "    @trainer.on(Events.EPOCH_COMPLETED)\n",
        "    def log_validation_results(trainer):\n",
        "        state = val_evaluator.run(testloader)\n",
        "        metrics = val_evaluator.state.metrics\n",
        "        accuracy = metrics['accuracy']*100\n",
        "        loss = metrics['ce']\n",
        "        log_metrics(val_evaluator.logger, state.epoch, state.times[\"COMPLETED\"], \"validation evaluator\", state.metrics)\n",
        "        #print(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
        "        #    .format(trainer.state.epoch, accuracy, loss))\n",
        "\n",
        "    trainer.run(trainloader, max_epochs=config[\"num_epochs\"])    "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEz3a666g4kl"
      },
      "source": [
        " 이제 아래 코드에서와 같이, 상황에 따라 적절한 숫자만큼 프로세스를 생성하여 분산처리를 시행한다.\n",
        "\n",
        " 코드 세부는 다음과 같다. 우선 시험에 필요한 설정들을 (라인 1-26)에서 딕셔너리(dictioinary)로 준비하였다. 그리고 (라인 28-38)에서 가속기 종류에 따라 백엔드로 xla-tup를 할당하는 등의 설정 작업을 지정한 후, (라인 51-52)에서 training 함수를 컨택스트 매니징이 가능한 idist.Parallel을 이용하여 run 시킨다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6457b4c36807480f9ee9c020640ee2d9",
            "7854623a62584e958127ff020ce55ed9",
            "a24a44f25e6e454d8c986d45242581cf",
            "ae38e46c9fec48c89135f7c2a8b55de2",
            "6041bf971e564762aa5235efcd86212f",
            "11afaea95b25462dba27f80cbb1f2beb",
            "d55271f163c24a3bb88b0bd336960722",
            "e238024fe5584031b78cad9238c4c4b4",
            "964b446e8c5742c88f9a0b14337ec7c8",
            "cbf4006615474038bb92d8dfde17e533",
            "1cafb7ab72c74fdc8ee36d846c37e060"
          ]
        },
        "id": "FXJzm8yqtI-k",
        "outputId": "0cad094c-8c36-4e22-c921-bb1cc4c4c981"
      },
      "source": [
        "config = {\n",
        "    \"seed\": 543,\n",
        "    \"data_path\" : \"./cifar10\",\n",
        "    \"output_path\" : \"./output-cifar10/\",\n",
        "    \"model\" : \"resnet18\",\n",
        "    \"batch_size\" : 512,\n",
        "    \"momentum\" : 0.9,\n",
        "    \"weight_decay\" : 1e-4,\n",
        "    \"num_workers\" : 2,\n",
        "    \"num_epochs\" : 5,\n",
        "    \"learning_rate\" : 0.4,\n",
        "    \"num_warmup_epochs\" : 4,\n",
        "    \"validate_every\" : 3, \n",
        "    \"checkpoint_every\" : 1000,\n",
        "    \"backend\" : None, \n",
        "    \"resume_from\" : None, \n",
        "    \"log_every_iters\" : 15,\n",
        "    \"nproc_per_node\" : None, \n",
        "    \"stop_iteration\" : None, \n",
        "    \"with_amp\" : False,\n",
        "    \"log_interval\" : 10,\n",
        "    \"verbose_set\" : False,\n",
        "    \"verbose_set2\" : False,\n",
        "    \"verbose_loader\" : False\n",
        "\n",
        "}\n",
        "\n",
        "if not (tpu_gtg or gpu_gtg): # cpu\n",
        "    config[\"backend\"] = 'gloo'\n",
        "    config[\"nproc_per_node\"] = 8\n",
        "elif gpu_gtg: # gpu\n",
        "    config[\"backend\"] = 'nccl'\n",
        "    config[\"nproc_per_node\"] = 1\n",
        "elif tpu_gtg: # tpu\n",
        "    config[\"backend\"] = 'xla-tpu'\n",
        "    config[\"nproc_per_node\"] = 8\n",
        "else: # error\n",
        "    raise RuntimeError(\"Unknown environment: tpu_gtg {}, gpu_gtg {}\".format(tpu_gtg, gpu_gtg))\n",
        "\n",
        "if config[\"backend\"] == \"xla-tpu\" and config[\"with_amp\"]:\n",
        "    raise RuntimeError(\"The value of with_amp should be False if backend is xla\")\n",
        "\n",
        "\n",
        "#dist_configs = {'nproc_per_node': config[\"nproc_per_node\"], \"start_method\": \"fork\"}  \n",
        "dist_configs = {'nproc_per_node': 1, \"start_method\": \"fork\"}  \n",
        "\n",
        "def log_metrics(logger, epoch, elapsed, tag, metrics):\n",
        "    metrics_output = \"\\n\".join([f\"\\t{k}: {v}\" for k, v in metrics.items()])\n",
        "    logger.info(f\"\\nEpoch {epoch} - Evaluation time (seconds): {elapsed:.2f} - {tag} metrics:\\n {metrics_output}\")\n",
        "\n",
        "with idist.Parallel(backend=config[\"backend\"], **dist_configs) as parallel:\n",
        "    parallel.run(training, config, a=1, b=1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-09-13 04:39:14,197 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'xla-tpu'\n",
            "2021-09-13 04:39:14,200 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: \n",
            "\tnproc_per_node: 1\n",
            "\tnnodes: 1\n",
            "\tnode_rank: 0\n",
            "\tstart_method: fork\n",
            "2021-09-13 04:39:14,202 ignite.distributed.launcher.Parallel INFO: Spawn function '<function training at 0x7f8066059ef0>' in 1 processes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "local rank:  0\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6457b4c36807480f9ee9c020640ee2d9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar10/cifar-10-python.tar.gz to ./cifar10\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-09-13 04:39:35,713 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': \n",
            "\t{'batch_size': 512, 'shuffle': True, 'num_workers': 2, 'drop_last': True, 'pin_memory': False}\n",
            "2021-09-13 04:39:35,716 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': \n",
            "\t{'batch_size': 512, 'shuffle': False, 'num_workers': 2, 'pin_memory': False}\n",
            "2021-09-13 04:39:36,636 hkim-trainer INFO: Engine run starting with max_epochs=5.\n",
            "2021-09-13 04:40:03,707 hkim-train_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 04:40:21,907 hkim-train_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:18\n",
            "2021-09-13 04:40:21,911 hkim-train_evaluator INFO: Engine run complete. Time taken: 00:00:18\n",
            "2021-09-13 04:40:21,937 hkim-train_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 18.20 - train evaluator metrics:\n",
            " \taccuracy: 0.4964763208762887\n",
            "\tce: 1.3828063650229543\n",
            "\tcm: tensor([[2024,  553,  178,  163,   70,  123,  160,   42, 1341,  312],\n",
            "        [ 147, 3694,   63,   72,   35,   40,  255,   35,  204,  425],\n",
            "        [ 356,  141, 1810,  508,  437,  686,  518,  138,  282,   90],\n",
            "        [  99,   81,  375, 1469,  285, 1645,  668,   97,  122,  124],\n",
            "        [ 158,   78, 1137,  238, 1643,  556,  479,  391,  145,  139],\n",
            "        [  38,   72,  322,  675,  259, 2995,  342,  130,   60,   80],\n",
            "        [  16,   79,  593,  317,  460,  326, 3023,   24,   68,   59],\n",
            "        [  63,  138,  219,  237,  518,  889,  194, 2373,   42,  295],\n",
            "        [ 298,  619,   57,   98,   43,   97,  103,    6, 3415,  226],\n",
            "        [ 116, 1628,   55,  117,   37,  106,  315,   69,  311, 2211]])\n",
            "2021-09-13 04:40:21,938 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 04:40:29,272 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
            "2021-09-13 04:40:29,275 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:07\n",
            "2021-09-13 04:40:29,299 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 7.33 - validation evaluator metrics:\n",
            " \taccuracy: 0.5036\n",
            "\tce: 1.36075107421875\n",
            "\tcm: tensor([[392, 110,  42,  11,   2,  17,  32,   3, 352,  39],\n",
            "        [ 29, 792,  15,   9,   2,  13,  30,   4,  39,  67],\n",
            "        [ 71,  23, 400,  76,  57, 170,  93,  21,  70,  19],\n",
            "        [ 25,  25,  81, 255,  43, 346, 145,  15,  41,  24],\n",
            "        [ 36,  11, 287,  36, 314, 122,  74,  69,  42,   9],\n",
            "        [ 12,   7,  74,  81,  54, 644,  64,  22,  33,   9],\n",
            "        [  5,  15, 143,  39,  92,  60, 615,   6,  18,   7],\n",
            "        [ 28,  22,  45,  39,  85, 198,  33, 475,  20,  55],\n",
            "        [ 47, 103,  10,   6,   7,  17,  15,   1, 764,  30],\n",
            "        [ 15, 396,  12,  18,   5,  14,  43,  10, 102, 385]])\n",
            "2021-09-13 04:40:29,300 hkim-trainer INFO: Epoch[1] Complete. Time taken: 00:00:53\n",
            "2021-09-13 04:40:51,092 hkim-train_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 04:41:05,913 hkim-train_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:15\n",
            "2021-09-13 04:41:05,916 hkim-train_evaluator INFO: Engine run complete. Time taken: 00:00:15\n",
            "2021-09-13 04:41:05,951 hkim-train_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 14.82 - train evaluator metrics:\n",
            " \taccuracy: 0.5701312822164949\n",
            "\tce: 1.1844421858640062\n",
            "\tcm: tensor([[2734,  270,  705,   53,   39,   14,   40,   63,  898,  155],\n",
            "        [ 203, 3907,   50,   30,    7,    3,   55,   34,  207,  469],\n",
            "        [ 248,  150, 2826,  354,  190,  133,  585,  229,  130,  120],\n",
            "        [ 101,  144,  708, 2041,  111,  505,  672,  322,  125,  235],\n",
            "        [ 242,  100,  997,  381, 1405,  107,  655,  855,   91,  136],\n",
            "        [  50,   88,  645, 1205,  126, 1740,  346,  551,   33,  175],\n",
            "        [  31,  153,  354,  309,  117,   51, 3713,   49,   52,  141],\n",
            "        [ 141,  109,  298,  270,  172,  161,  110, 3352,   18,  334],\n",
            "        [ 355,  332,  151,   82,   25,   10,   32,   17, 3738,  222],\n",
            "        [ 276, 1303,   59,   49,   10,   10,   55,   73,  278, 2859]])\n",
            "2021-09-13 04:41:05,953 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 04:41:08,802 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 04:41:08,806 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:03\n",
            "2021-09-13 04:41:08,830 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 2.85 - validation evaluator metrics:\n",
            " \taccuracy: 0.6047\n",
            "\tce: 1.1137271484375\n",
            "\tcm: tensor([[588,  33, 115,   7,   9,   1,  16,  13, 193,  25],\n",
            "        [ 34, 802,  11,   5,   3,   1,  14,   7,  43,  80],\n",
            "        [ 54,  17, 553,  63,  45,  65, 112,  43,  25,  23],\n",
            "        [ 24,  25, 106, 405,  28, 176, 120,  53,  20,  43],\n",
            "        [ 48,  14, 156,  56, 333,  42, 143, 172,  20,  16],\n",
            "        [ 15,   8, 105, 149,  28, 498,  64, 103,  14,  16],\n",
            "        [  6,  15,  54,  60,  14,  25, 788,   7,  18,  13],\n",
            "        [ 39,  16,  42,  44,  36,  62,  20, 698,   1,  42],\n",
            "        [ 70,  59,  13,  17,   4,   4,   6,   9, 787,  31],\n",
            "        [ 47, 241,   9,   7,   3,   4,  10,  13,  71, 595]])\n",
            "2021-09-13 04:41:08,831 hkim-trainer INFO: Epoch[2] Complete. Time taken: 00:00:40\n",
            "2021-09-13 04:41:24,589 hkim-train_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 04:41:39,460 hkim-train_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:15\n",
            "2021-09-13 04:41:39,464 hkim-train_evaluator INFO: Engine run complete. Time taken: 00:00:15\n",
            "2021-09-13 04:41:39,492 hkim-train_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 14.87 - train evaluator metrics:\n",
            " \taccuracy: 0.6148719394329897\n",
            "\tce: 1.0706503956588274\n",
            "\tcm: tensor([[2368,  210,  326,  136,  219,   18,   10,  221,  908,  547],\n",
            "        [  47, 3364,   28,   57,   19,   16,   16,   62,  191, 1159],\n",
            "        [ 218,   77, 2325,  399,  817,  291,  202,  380,  115,  143],\n",
            "        [  59,   48,  317, 2433,  294,  885,  216,  422,  107,  178],\n",
            "        [  83,   28,  172,  364, 2843,  123,  128, 1055,   66,  104],\n",
            "        [  11,   48,  286, 1131,  261, 2474,   45,  560,   35,  116],\n",
            "        [  21,  104,  251,  574,  553,  212, 2813,  185,   53,  206],\n",
            "        [  12,   45,  115,  200,  210,  288,   16, 3882,   23,  187],\n",
            "        [ 109,  209,   41,   89,   69,   27,    6,   33, 3899,  477],\n",
            "        [  43,  359,   27,   53,   20,   25,    8,  166,  137, 4136]])\n",
            "2021-09-13 04:41:39,494 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 04:41:42,303 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 04:41:42,306 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:03\n",
            "2021-09-13 04:41:42,337 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 2.81 - validation evaluator metrics:\n",
            " \taccuracy: 0.6361\n",
            "\tce: 1.02058076171875\n",
            "\tcm: tensor([[558,  21,  62,  21,  32,   8,   7,  25, 173,  93],\n",
            "        [ 13, 714,   3,   9,   2,   4,   5,   8,  29, 213],\n",
            "        [ 51,   6, 475,  65, 128, 110,  53,  62,  30,  20],\n",
            "        [  9,  12,  70, 459,  48, 230,  50,  67,  17,  38],\n",
            "        [ 11,   6,  34,  83, 545,  51,  42, 209,  12,   7],\n",
            "        [  8,   5,  42, 178,  33, 620,   7,  81,  13,  13],\n",
            "        [  8,   8,  51, 105,  78,  62, 621,  34,   8,  25],\n",
            "        [  7,   4,  32,  42,  35,  82,   3, 755,   3,  37],\n",
            "        [ 36,  37,   3,  13,   9,   4,   0,   9, 812,  77],\n",
            "        [ 15,  87,   8,  23,   1,   7,   3,  19,  35, 802]])\n",
            "2021-09-13 04:41:42,339 hkim-trainer INFO: Epoch[3] Complete. Time taken: 00:00:34\n",
            "2021-09-13 04:41:58,156 hkim-train_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 04:42:13,133 hkim-train_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:15\n",
            "2021-09-13 04:42:13,138 hkim-train_evaluator INFO: Engine run complete. Time taken: 00:00:15\n",
            "2021-09-13 04:42:13,164 hkim-train_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 14.98 - train evaluator metrics:\n",
            " \taccuracy: 0.653894168814433\n",
            "\tce: 0.9722710049029478\n",
            "\tcm: tensor([[3678,  347,  171,   86,   90,   27,   30,   96,  368,   71],\n",
            "        [  76, 4426,   17,   29,   10,   16,   66,   23,  177,  113],\n",
            "        [ 507,  104, 2394,  343,  645,  288,  317,  270,   73,   25],\n",
            "        [ 129,  107,  291, 2389,  403,  857,  334,  348,   64,   43],\n",
            "        [ 262,   47,  288,  210, 3121,  114,  237,  617,   44,   22],\n",
            "        [  46,   47,  237,  962,  330, 2686,  159,  446,   26,   30],\n",
            "        [  46,  100,  207,  399,  340,  108, 3653,   72,   26,   20],\n",
            "        [ 109,   52,  114,  172,  336,  227,   43, 3849,   21,   49],\n",
            "        [ 448,  272,   32,   92,   29,   13,   18,   21, 3972,   70],\n",
            "        [ 210, 1878,   29,   78,   23,   38,   80,  143,  189, 2307]])\n",
            "2021-09-13 04:42:13,166 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 04:42:16,108 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 04:42:16,114 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:03\n",
            "2021-09-13 04:42:16,138 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 2.95 - validation evaluator metrics:\n",
            " \taccuracy: 0.6618\n",
            "\tce: 0.97043515625\n",
            "\tcm: tensor([[778,  62,  26,  12,  23,   5,  11,  12,  56,  15],\n",
            "        [ 14, 887,   7,   5,   2,   3,  20,   5,  21,  36],\n",
            "        [121,   7, 428,  66, 145,  79,  75,  68,   5,   6],\n",
            "        [ 17,  17,  59, 479,  88, 178,  73,  65,  13,  11],\n",
            "        [ 57,   4,  40,  37, 638,  32,  65, 117,   7,   3],\n",
            "        [ 18,   8,  36, 164,  64, 589,  24,  86,   6,   5],\n",
            "        [ 11,  10,  24,  78,  62,  18, 773,  20,   3,   1],\n",
            "        [ 28,  15,  26,  26,  45,  47,  10, 792,   2,   9],\n",
            "        [104,  56,   6,  17,   5,   5,   3,   9, 782,  13],\n",
            "        [ 43, 375,  11,  16,   4,   7,  19,  23,  30, 472]])\n",
            "2021-09-13 04:42:16,140 hkim-trainer INFO: Epoch[4] Complete. Time taken: 00:00:34\n",
            "2021-09-13 04:42:32,619 hkim-train_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 04:42:47,898 hkim-train_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:15\n",
            "2021-09-13 04:42:47,901 hkim-train_evaluator INFO: Engine run complete. Time taken: 00:00:15\n",
            "2021-09-13 04:42:47,930 hkim-train_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 15.28 - train evaluator metrics:\n",
            " \taccuracy: 0.6701634987113402\n",
            "\tce: 0.9386687131272149\n",
            "\tcm: tensor([[3079,   85,  380,   97,  194,   66,   34,  245,  651,  136],\n",
            "        [ 125, 3798,   64,   59,   38,   68,   89,  151,  311,  256],\n",
            "        [ 232,   15, 3022,  354,  331,  482,  175,  263,   72,   20],\n",
            "        [  51,   17,  318, 2294,  179, 1470,  156,  395,   59,   30],\n",
            "        [  51,    6,  370,  334, 2779,  288,  159,  934,   47,    7],\n",
            "        [   7,   10,  197,  599,  134, 3553,   39,  396,   14,   11],\n",
            "        [  25,   26,  271,  668,  208,  346, 3256,  111,   28,   20],\n",
            "        [  26,   10,  136,  122,  114,  447,   15, 4056,   10,   31],\n",
            "        [ 137,   81,   69,   72,   72,   53,   35,   47, 4324,   83],\n",
            "        [ 118,  630,   53,   85,   79,  122,   36,  470,  254, 3122]])\n",
            "2021-09-13 04:42:47,932 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 04:42:50,801 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 04:42:50,804 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:03\n",
            "2021-09-13 04:42:50,831 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 2.87 - validation evaluator metrics:\n",
            " \taccuracy: 0.6783\n",
            "\tce: 0.94813466796875\n",
            "\tcm: tensor([[666,  17,  68,  17,  45,   7,   6,  26, 127,  21],\n",
            "        [ 20, 800,   8,  16,   6,  13,  15,  22,  62,  38],\n",
            "        [ 60,   4, 583,  58,  80, 112,  31,  55,  13,   4],\n",
            "        [ 11,   3,  69, 433,  43, 315,  35,  65,  20,   6],\n",
            "        [  9,   1,  72,  53, 593,  60,  32, 169,  10,   1],\n",
            "        [  7,   3,  43,  95,  27, 741,   7,  70,   4,   3],\n",
            "        [  6,   2,  62, 102,  46,  86, 669,  18,   8,   1],\n",
            "        [  5,   3,  30,  13,  27,  93,   3, 820,   4,   2],\n",
            "        [ 26,  14,   9,   8,  13,  17,   5,  10, 889,   9],\n",
            "        [ 24, 162,  17,  15,  14,  22,   8,  88,  61, 589]])\n",
            "2021-09-13 04:42:50,833 hkim-trainer INFO: Epoch[5] Complete. Time taken: 00:00:35\n",
            "2021-09-13 04:42:50,834 hkim-trainer INFO: Engine run complete. Time taken: 00:03:14\n",
            "2021-09-13 04:42:50,866 ignite.distributed.launcher.Parallel INFO: End of run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQL39wXmXx9k"
      },
      "source": [
        "## License\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXio6q3iX5Ig"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "Note: This is not an official [LG AI Research](https://www.lgresearch.ai/) product but sample code provided for an educational purpose\n",
        "\n",
        "<br/>\n",
        "author: John H. Kim\n",
        "<br/>  \n",
        "email: john.kim@lgresearch.ai / secutron@naver.com  \n",
        "\n",
        "\n",
        "---"
      ]
    }
  ]
}