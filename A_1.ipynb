{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A.1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMffZGMD2QR5jhQIJVW4RFD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ffcb8ebd69d4477d9a10cf197756a675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dd08a66f822f4e498e216da7501c97fd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e81c90c08fdf4470bebab95064ee7df8",
              "IPY_MODEL_85c8efd45f0d45af8405c052daebc2d5",
              "IPY_MODEL_474fb84acb7047f9a281f56af60b047b"
            ]
          }
        },
        "dd08a66f822f4e498e216da7501c97fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e81c90c08fdf4470bebab95064ee7df8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b6bc5064c61471bbc9577c8a0284baa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8228b0bf58614cafa148059b48d81586"
          }
        },
        "85c8efd45f0d45af8405c052daebc2d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4ec282f8d33540779e44c37bf1e3c6f4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8f9085d92c24ad5903e36d3dac3cf86"
          }
        },
        "474fb84acb7047f9a281f56af60b047b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3547eed2097c49abb86cfbddb2b3f587",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:03&lt;00:00, 61418884.99it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f15a434ae9ce468787e7654a18125239"
          }
        },
        "8b6bc5064c61471bbc9577c8a0284baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8228b0bf58614cafa148059b48d81586": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ec282f8d33540779e44c37bf1e3c6f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8f9085d92c24ad5903e36d3dac3cf86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3547eed2097c49abb86cfbddb2b3f587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f15a434ae9ce468787e7654a18125239": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/secutron/Practice_Ignite/blob/main/A_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfVeNJIVYVu9"
      },
      "source": [
        "## Resnet18 + CIFAR10 on CPU/TPU/GPU using 'ignite'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK6Pe16EpvP3"
      },
      "source": [
        "##A.1. 속성 예제 \n",
        "\n",
        " 때로는 역순으로, 완결 코드로부터 시작하여 궁금한 부분만 선택적으로 확인하는 것이 더 효율적일 때가 있다. 이를 위해 이그나이트([ignite](https://pytorch.org/ignite/))의 [auto_dataloader](https://pytorch.org/ignite/v0.4.6/generated/ignite.distributed.auto.auto_dataloader.html#auto-dataloader)와 [auto_model](https://pytorch.org/ignite/v0.4.6/generated/ignite.distributed.auto.auto_model.html#ignite.distributed.auto.auto_model), [auto_optim](https://pytorch.org/ignite/v0.4.6/generated/ignite.distributed.auto.auto_optim.html#ignite.distributed.auto.auto_optim), 그리고 트레이너(trainer)와 이벤트 핸들러(event handler)등의 중요한 부분을  포함하는, 구글 colab 기반의 속성 예제 코드를 아래와 같이 준비하였다.\n",
        "\n",
        " 그리고 이그나이트([ignite](https://pytorch.org/ignite/))는 작성 시점을 기준으로 다음의 커뮤니케이션 백엔드들을 지원한다.\n",
        "\n",
        "- backends from native torch distributed configuration: “nccl”, “gloo”, “mpi”\n",
        "- XLA on TPUs via pytorch/xla\n",
        "- using Horovod framework as a backend\n",
        "\n",
        "*커뮤니케이션 백엔드: 상기 ‘’’1.4 분산 딥러닝 기본 지식’’’ 항목에서 언급된 바와 같이 분산처리를 위해서는 컴퓨팅 코어 간 통신이 필요하며, 만일 이 컴퓨팅 코어가 CPU인 경우 gloo나 mpi 백엔드, GPU 경우에는 nccl 백엔드, TPU 경우에는 xla 백엔드 이용이 가능하다. 이와 관련한 보다 상세한 내용은 DISTRIBUTED COMMUNICATION PACKAGE - TORCH.DISTRIBUTED 페이지의 [rule of thumb](https://pytorch.org/docs/stable/distributed.html) 항목을 참조한다. ---~~분산처리의 역사만큼이나 다양한 분산처리 방식이 존재한다. TCP 등을 이용해 직접 프로세스간 통신을 처리하는 방법도 있지만, 하이레벨 관점에서 CPU는 gloo, GPU는 nccl, TPU는 xla 백엔드를 사용해야 한다고 생각하는 것이 정신건강에 좋다.~~---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT0sitfdvGKS"
      },
      "source": [
        "###A.1.1. Colab runtime 설정\n",
        "\n",
        " 분산처리에 익숙하지 않은 개발자의 경우, 구글 colab을 이용하여 DDL(Distributed Deep Learning)의 기초를 연습하는 것이 여러 면에서 장점이 있다. 우선 가장 중요한 것은 CPU와 GPU, 그리고 TPU 환경을 쉽게 번갈아가며 분산처리 코드의 동작 상태를 확인할 수 있다는 점이다. ~~그리고 아직 colab은 무료이다. 럭셔리한 환경이라면 GCP를 사용해도 좋겠지.~~ \n",
        "\n",
        " 다만 아쉽게도 현 시점에서 colab 무료 버전을 사용하는 경우, 멀티 GPU(Multi-GPU)나 멀티 노드(Multi-Node) 환경은 테스트할 수 없다. 하지만 이그나이트([ignite](https://pytorch.org/ignite/))에서는 작성한 단일 코드를 다양한 환경에서 동일하게 사용할 수 있으므로, 가능한 편안한 환경에서 코드 개발을 선행하고 이후 멀티노드와 같은 목표 환경으로 옮기는 작업 방식을 추천한다. \n",
        "\n",
        "  Colab에서는 아래 그림에서와 같이 런타임 환경 설정을 통해 CPU와 GPU, TPU 사용을 선택할 수 있다. ~~하드웨어 가속기가 None이면 CPU만 있다는 뜻~~\n",
        "\n",
        " <div align=\"center\">\n",
        "<img width=512 src=\"https://i.imgur.com/gcm9MlH.png\"/>\n",
        "</div>\n",
        "\n",
        " 런타임 변경이 발생할 때마다 새로운 VM(Virtual Machine)이 할당되며, 기존 노트 셀(cell)을  실행시킨 내용이 모두 사라지게 되므로 이에 주의한다. ---~~코드 수정이 사라지는  것이 아니라 셀 실행한 내용이 사라지게 되는 것이다. 예를 들어 셀 실행을 통해 학습 데이터를 VM에 내려받은 경우, 런타임 변경을 통해 새롭게 VM이 할당될 경우 기존 내려받은 데이터는 당연히 새로운 VM에서 찾아볼 수 없다.~~---\n",
        "\n",
        "  그리고 TPU를 통해 분산처리를 진행하는 경우, 특별히 colab runtime을 TPU 구동이 가능한 VM으로 환경을 설정해주는 작업이  필요하다. 이를 위해 아래와 같은 코드로 colab의 runtime type이 TPU인지 먼저 확인한다. 그리고 검출된 환경이 TPU인 경우, 분산처리가 가능한 런타임으로 변경하는 작업을 수행한다. 참고로 GPU 사용 시에는 런타임 유형 변경에서 GPU를 선택하는 것만으로 GPU를 사용할 수 있다. \n",
        "\n",
        " 다행히 파이토치 커뮤니티에서는 아래와 같이 사용이 편리한 xla 설정 관련 스크립트를 제공하고 있다. \n",
        "\n",
        " ** 가이드라인 작성 시점 기준 잔여 issue로, 20210304 version으로 지정함\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdhoeHGgsimM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "706a0b12-e4ba-47c2-8599-8e38ea5c76eb"
      },
      "source": [
        "import os\n",
        "\n",
        "gpu_gtg = False\n",
        "if int(os.environ.get(\"COLAB_GPU\")) > 0:\n",
        "    gpu_gtg = \"COLAB_GPU\" in os.environ\n",
        "\n",
        "tpu_gtg = \"COLAB_TPU_ADDR\" in os.environ\n",
        "\n",
        "if tpu_gtg: # tpu\n",
        "    print(\"TPU\")\n",
        "    #VERSION = \"nightly\"\n",
        "\n",
        "    # https://github.com/pytorch/builder/pull/750\n",
        "    VERSION = \"20210304\" # was 20200607\" \n",
        "\n",
        "    !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "    !python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TPU\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  5116  100  5116    0     0  66441      0 --:--:-- --:--:-- --:--:-- 66441\n",
            "Updating... This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-dev20210304 ...\n",
            "Found existing installation: torch 1.9.0+cu102\n",
            "Collecting cloud-tpu-client\n",
            "  Downloading cloud_tpu_client-0.10-py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client) (4.1.3)\n",
            "Collecting google-api-python-client==1.8.0\n",
            "  Downloading google_api_python_client-1.8.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.15.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (3.0.1)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.34.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.26.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.53.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (21.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2018.9)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.17.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.4)\n",
            "Uninstalling torch-1.9.0+cu102:\n",
            "Installing collected packages: google-api-python-client, cloud-tpu-client\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 1.12.8\n",
            "    Uninstalling google-api-python-client-1.12.8:\n",
            "      Successfully uninstalled google-api-python-client-1.12.8\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "earthengine-api 0.1.278 requires google-api-python-client<2,>=1.12.1, but you have google-api-python-client 1.8.0 which is incompatible.\u001b[0m\n",
            "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0\n",
            "  Successfully uninstalled torch-1.9.0+cu102\n",
            "Found existing installation: torchvision 0.10.0+cu102\n",
            "Uninstalling torchvision-0.10.0+cu102:\n",
            "  Successfully uninstalled torchvision-0.10.0+cu102\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20210304-cp37-cp37m-linux_x86_64.whl...\n",
            "\\ [1 files][126.5 MiB/126.5 MiB]                                                \n",
            "Operation completed over 1 objects/126.5 MiB.                                    \n",
            "Done updating TPU runtime\n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20210304-cp37-cp37m-linux_x86_64.whl...\n",
            "\\ [1 files][138.1 MiB/138.1 MiB]                                                \n",
            "Operation completed over 1 objects/138.1 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20210304-cp37-cp37m-linux_x86_64.whl...\n",
            "/ [1 files][  4.6 MiB/  4.6 MiB]                                                \n",
            "Operation completed over 1 objects/4.6 MiB.                                      \n",
            "Processing ./torch-nightly+20210304-cp37-cp37m-linux_x86_64.whl\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==nightly+20210304) (3.7.4.3)\n",
            "Installing collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 1.0.61 requires torchvision, which is not installed.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.9.0a0+gitc4c77e2 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0a0+gitc4c77e2\n",
            "Processing ./torch_xla-nightly+20210304-cp37-cp37m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "Successfully installed torch-xla-1.9+e6237f2\n",
            "Processing ./torchvision-nightly+20210304-cp37-cp37m-linux_x86_64.whl\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==nightly+20210304) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==nightly+20210304) (1.19.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchvision==nightly+20210304) (1.9.0a0+gitc4c77e2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchvision==nightly+20210304) (3.7.4.3)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.9.0a0+7d41547\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libomp5\n",
            "0 upgraded, 1 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 234 kB of archives.\n",
            "After this operation, 774 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Fetched 234 kB in 1s (328 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 148492 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNby47f71vRB"
      },
      "source": [
        "###A.1.2. 패키지 설치\n",
        "\n",
        " 다음과 같이 이그나이트의 최신 version을 설치한다. 현 시점 기준 Colab에서 제공하는 VM은, 이그나이트가 사전 설치되어 있지 않은 상태이기 때문이다.  ~~참고로 pip 명령어는 package installer for python)의 약자이며, 아래 명령문 실행 시 이그나이트의 pre-release를 PyPI(python package index)로부터 설치하게 된다.~~\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27ND-qg2tJEU",
        "outputId": "29295adb-9356-4362-85da-f9fc64b8e273"
      },
      "source": [
        "!pip install --pre pytorch-ignite"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.5.0.dev20210913-py3-none-any.whl (233 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20 kB 20.4 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 40 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 81 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 233 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.9.0a0+gitc4c77e2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.5.0.dev20210913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5OggR1m2NTU"
      },
      "source": [
        "상기 결과에 따르면, 본 가이드라인 작성 시점의 최신 버전인 xxxx년 x월 xx일자 (예: 2021년 9월 10일자) 이그나이트 x.x.x (예: 0.5.0)가 설치 되었음을 알 수 있다.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlmKaoMc2PEs"
      },
      "source": [
        "###A.1.3. 분산 트레이닝 코드\n",
        "\n",
        "이제 필요한 환경이 적절히 준비되었으므로, 필요한 패키지를 아래 코드에서와 같이 로드한다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYoQTy8JtJBU"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, models\n",
        "\n",
        "import torchsummary\n",
        "\n",
        "import ignite\n",
        "import ignite.distributed as idist\n",
        "from ignite.engine import Engine, Events, create_supervised_evaluator, create_supervised_trainer\n",
        "from ignite.metrics import Accuracy, Loss, RunningAverage, ConfusionMatrix\n",
        "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
        "from ignite.utils import setup_logger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0bZaFYCggop"
      },
      "source": [
        " 그리고 병렬 처리될 training 함수 내에서 파이토치 사용 시와 동일하게 dataloader 처리를 진행한다. 이그나이트는 파이토치 기반의 wrapper이며, dataloader나 모델 architecturing 등은 기존 파이토치의 모델 학습 시의 pipeline 을 그대로 이용한다. 따라서 파이토치에 익숙하지 않을 경우 가이드라인 이해가 어려울 수 있음을 서문에서 언급한 바 있다.\n",
        "\n",
        " 그 외 이그나이트에서 지원하는 auto_dataloader와 auto_model, auto_optim, 그리고 트레이너(trainer)와 이벤트 핸들러(event handler) 등의 중요한 부분을 아래와 같이 구현한다. 일반적인 지도학습(supervised learning)의 경우 이그나이트를 이용해 매우 간단하게 구현할 수 있음을 확인할 수 있다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va-GVsDLyijz"
      },
      "source": [
        "def training(local_rank, config, **kwargs):\n",
        "    print(\"local rank: \", local_rank)\n",
        "\n",
        "    ###########################################################\n",
        "    # 데이터 준비\n",
        "    train_transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Pad(4),\n",
        "            transforms.RandomCrop(32, fill=128),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    test_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),])\n",
        "\n",
        "    if idist.get_local_rank() > 0:\n",
        "        idist.barrier()\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root=config[\"data_path\"], train=True, download=True, transform=train_transform)\n",
        "    testset = torchvision.datasets.CIFAR10(root=config[\"data_path\"], train=False, download=True, transform=test_transform)\n",
        "\n",
        "    if idist.get_local_rank() == 0:\n",
        "        idist.barrier()\n",
        "\n",
        "    trainloader = idist.auto_dataloader(trainset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=config[\"num_workers\"], drop_last=True)\n",
        "    testloader = idist.auto_dataloader(testset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=config[\"num_workers\"],)\n",
        "\n",
        "\n",
        "    ###########################################################\n",
        "    # 모델, 옵티마이저, 로스, 트레이너, 이밸류에이터\n",
        "    num_classes = 10\n",
        "    model = models.resnet18(num_classes = num_classes)\n",
        "       \n",
        "    model = idist.auto_model(model)\n",
        "    optimizer = idist.auto_optim(optim.Adam(model.parameters(), lr=0.001))\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss().to(idist.device())\n",
        "\n",
        "    trainer = create_supervised_trainer(model, optimizer, criterion, device=idist.device())\n",
        "    trainer.logger = setup_logger(\"hkim-trainer\")\n",
        "\n",
        "    metrics = {\n",
        "        'accuracy':Accuracy(),\n",
        "        'ce':Loss(criterion),\n",
        "    }\n",
        "\n",
        "    val_evaluator = create_supervised_evaluator(model, metrics=metrics, device=idist.device())\n",
        "    val_evaluator.logger = setup_logger(\"hkim-val_evaluator\")\n",
        "\n",
        "    # track a running average of the scalar loss output for each batch.\n",
        "    RunningAverage(output_transform=lambda x: x).attach(trainer, 'loss')\n",
        "\n",
        "    ###########################################################\n",
        "    # 이벤트\n",
        "\n",
        "    @trainer.on(Events.EPOCH_COMPLETED)\n",
        "    def log_validation_results(trainer):\n",
        "        state = val_evaluator.run(testloader)\n",
        "        metrics = val_evaluator.state.metrics\n",
        "        accuracy = metrics['accuracy']*100\n",
        "        loss = metrics['ce']\n",
        "        log_metrics(val_evaluator.logger, state.epoch, state.times[\"COMPLETED\"], \"validation evaluator\", state.metrics)\n",
        "\n",
        "    trainer.run(trainloader, max_epochs=config[\"num_epochs\"])    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEz3a666g4kl"
      },
      "source": [
        " 이제 아래 코드에서와 같이, 상황에 따라 적절한 숫자만큼 프로세스를 생성하여 분산처리를 시행한다.\n",
        "\n",
        " 코드 세부는 다음과 같다. 우선 시험에 필요한 설정들을 (라인 1-26)에서 딕셔너리(dictioinary)로 준비하였다. 그리고 (라인 28-38)에서 가속기 종류에 따라 백엔드로 xla-tup를 할당하는 등의 설정 작업을 지정한 후, (라인 51-52)에서 training 함수를 컨택스트 매니징이 가능한 idist.Parallel을 이용하여 run 시킨다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ffcb8ebd69d4477d9a10cf197756a675",
            "dd08a66f822f4e498e216da7501c97fd",
            "e81c90c08fdf4470bebab95064ee7df8",
            "85c8efd45f0d45af8405c052daebc2d5",
            "474fb84acb7047f9a281f56af60b047b",
            "8b6bc5064c61471bbc9577c8a0284baa",
            "8228b0bf58614cafa148059b48d81586",
            "4ec282f8d33540779e44c37bf1e3c6f4",
            "a8f9085d92c24ad5903e36d3dac3cf86",
            "3547eed2097c49abb86cfbddb2b3f587",
            "f15a434ae9ce468787e7654a18125239"
          ]
        },
        "id": "FXJzm8yqtI-k",
        "outputId": "363a65d3-c2d9-42bf-8a87-759a9cfb5ce0"
      },
      "source": [
        "config = {\n",
        "    \"seed\": 543,\n",
        "    \"data_path\" : \"./cifar10\",\n",
        "    \"output_path\" : \"./output-cifar10/\",\n",
        "    \"model\" : \"resnet18\",\n",
        "    \"batch_size\" : 512,\n",
        "    \"momentum\" : 0.9,\n",
        "    \"weight_decay\" : 1e-4,\n",
        "    \"num_workers\" : 2,\n",
        "    \"num_epochs\" : 24,\n",
        "    \"learning_rate\" : 0.4,\n",
        "    \"num_warmup_epochs\" : 4,\n",
        "    \"validate_every\" : 3, \n",
        "    \"checkpoint_every\" : 1000,\n",
        "    \"backend\" : None, \n",
        "    \"resume_from\" : None, \n",
        "    \"log_every_iters\" : 15,\n",
        "    \"nproc_per_node\" : None, \n",
        "    \"stop_iteration\" : None, \n",
        "    \"with_amp\" : False,\n",
        "    \"log_interval\" : 10,\n",
        "    \"verbose_set\" : False,\n",
        "    \"verbose_set2\" : False,\n",
        "    \"verbose_loader\" : False\n",
        "\n",
        "}\n",
        "\n",
        "if not (tpu_gtg or gpu_gtg): # cpu\n",
        "    config[\"backend\"] = 'gloo'\n",
        "    config[\"nproc_per_node\"] = 8\n",
        "elif gpu_gtg: # gpu\n",
        "    config[\"backend\"] = 'nccl'\n",
        "    config[\"nproc_per_node\"] = 1\n",
        "elif tpu_gtg: # tpu\n",
        "    config[\"backend\"] = 'xla-tpu'\n",
        "    config[\"nproc_per_node\"] = 8\n",
        "else: # error\n",
        "    raise RuntimeError(\"Unknown environment: tpu_gtg {}, gpu_gtg {}\".format(tpu_gtg, gpu_gtg))\n",
        "\n",
        "if config[\"backend\"] == \"xla-tpu\" and config[\"with_amp\"]:\n",
        "    raise RuntimeError(\"The value of with_amp should be False if backend is xla\")\n",
        "\n",
        "\n",
        "dist_configs = {'nproc_per_node': config[\"nproc_per_node\"], \"start_method\": \"fork\"}  \n",
        "\n",
        "def log_metrics(logger, epoch, elapsed, tag, metrics):\n",
        "    metrics_output = \"\\n\".join([f\"\\t{k}: {v}\" for k, v in metrics.items()])\n",
        "    logger.info(f\"\\nEpoch {epoch} - Evaluation time (seconds): {elapsed:.2f} - {tag} metrics:\\n {metrics_output}\")\n",
        "\n",
        "with idist.Parallel(backend=config[\"backend\"], **dist_configs) as parallel:\n",
        "    parallel.run(training, config, a=1, b=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-09-13 07:43:17,782 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'xla-tpu'\n",
            "2021-09-13 07:43:17,784 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: \n",
            "\tnproc_per_node: 8\n",
            "\tnnodes: 1\n",
            "\tnode_rank: 0\n",
            "\tstart_method: fork\n",
            "2021-09-13 07:43:17,786 ignite.distributed.launcher.Parallel INFO: Spawn function '<function training at 0x7fa2a1e58cb0>' in 8 processes\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "local rank:  7\n",
            "local rank:  2\n",
            "local rank:  5\n",
            "local rank:  1\n",
            "local rank:  3\n",
            "local rank:  6\n",
            "local rank:  4\n",
            "local rank:  0\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ffcb8ebd69d4477d9a10cf197756a675",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./cifar10/cifar-10-python.tar.gz to ./cifar10\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-09-13 07:44:48,697 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': \n",
            "\t{'batch_size': 64, 'num_workers': 2, 'drop_last': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x7fa2b316a450>, 'pin_memory': False}\n",
            "2021-09-13 07:44:48,719 ignite.distributed.auto.auto_dataloader INFO: DataLoader is wrapped by `MpDeviceLoader` on XLA\n",
            "2021-09-13 07:44:48,740 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': \n",
            "\t{'batch_size': 64, 'num_workers': 2, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x7fa29afa2050>, 'pin_memory': False}\n",
            "2021-09-13 07:44:48,753 ignite.distributed.auto.auto_dataloader INFO: DataLoader is wrapped by `MpDeviceLoader` on XLA\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-09-13 07:44:50,868 hkim-trainer INFO: Engine run starting with max_epochs=24.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-09-13 07:45:45,149 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:45:50,900 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:06\n",
            "2021-09-13 07:45:50,918 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:06\n",
            "2021-09-13 07:45:50,926 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 5.76 - validation evaluator metrics:\n",
            " \taccuracy: 0.5083\n",
            "\tce: 1.3657859375\n",
            "2021-09-13 07:45:50,930 hkim-trainer INFO: Epoch[1] Complete. Time taken: 00:00:60\n",
            "2021-09-13 07:46:23,184 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:46:26,740 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:46:26,750 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:46:26,759 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.54 - validation evaluator metrics:\n",
            " \taccuracy: 0.5722\n",
            "\tce: 1.19976494140625\n",
            "2021-09-13 07:46:26,771 hkim-trainer INFO: Epoch[2] Complete. Time taken: 00:00:36\n",
            "2021-09-13 07:46:58,130 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:47:01,713 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:47:01,734 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:47:01,746 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.59 - validation evaluator metrics:\n",
            " \taccuracy: 0.6515\n",
            "\tce: 1.002620703125\n",
            "2021-09-13 07:47:01,765 hkim-trainer INFO: Epoch[3] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:47:33,016 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:47:36,575 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:47:36,593 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:47:36,607 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.56 - validation evaluator metrics:\n",
            " \taccuracy: 0.6691\n",
            "\tce: 0.9666755859375\n",
            "2021-09-13 07:47:36,633 hkim-trainer INFO: Epoch[4] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:48:07,789 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:48:11,357 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:48:11,372 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:48:11,388 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.57 - validation evaluator metrics:\n",
            " \taccuracy: 0.7045\n",
            "\tce: 0.85864794921875\n",
            "2021-09-13 07:48:11,399 hkim-trainer INFO: Epoch[5] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:48:42,872 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:48:46,454 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:48:46,468 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:48:46,484 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.59 - validation evaluator metrics:\n",
            " \taccuracy: 0.7119\n",
            "\tce: 0.83871806640625\n",
            "2021-09-13 07:48:46,508 hkim-trainer INFO: Epoch[6] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:49:18,173 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:49:21,721 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:49:21,737 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:49:21,767 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.54 - validation evaluator metrics:\n",
            " \taccuracy: 0.7169\n",
            "\tce: 0.8235662109375\n",
            "2021-09-13 07:49:21,789 hkim-trainer INFO: Epoch[7] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:49:53,025 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:49:56,617 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:49:56,634 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:49:56,648 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.59 - validation evaluator metrics:\n",
            " \taccuracy: 0.7206\n",
            "\tce: 0.82320224609375\n",
            "2021-09-13 07:49:56,665 hkim-trainer INFO: Epoch[8] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:50:28,430 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:50:31,960 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:50:31,977 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:50:31,996 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.53 - validation evaluator metrics:\n",
            " \taccuracy: 0.7455\n",
            "\tce: 0.74374326171875\n",
            "2021-09-13 07:50:32,020 hkim-trainer INFO: Epoch[9] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:51:03,536 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:51:07,094 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:51:07,115 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:51:07,138 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.56 - validation evaluator metrics:\n",
            " \taccuracy: 0.7411\n",
            "\tce: 0.75353056640625\n",
            "2021-09-13 07:51:07,161 hkim-trainer INFO: Epoch[10] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:51:38,599 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:51:42,234 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:04\n",
            "2021-09-13 07:51:42,254 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:51:42,270 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.64 - validation evaluator metrics:\n",
            " \taccuracy: 0.7564\n",
            "\tce: 0.7184125\n",
            "2021-09-13 07:51:42,291 hkim-trainer INFO: Epoch[11] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:52:13,703 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:52:17,245 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:52:17,267 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:52:17,282 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.56 - validation evaluator metrics:\n",
            " \taccuracy: 0.7616\n",
            "\tce: 0.6881111328125\n",
            "2021-09-13 07:52:17,304 hkim-trainer INFO: Epoch[12] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:52:48,712 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:52:52,225 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:52:52,242 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:52:52,264 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.52 - validation evaluator metrics:\n",
            " \taccuracy: 0.7654\n",
            "\tce: 0.699411962890625\n",
            "2021-09-13 07:52:52,277 hkim-trainer INFO: Epoch[13] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:53:23,473 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:53:27,002 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:53:27,007 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:53:27,013 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.51 - validation evaluator metrics:\n",
            " \taccuracy: 0.7669\n",
            "\tce: 0.70954326171875\n",
            "2021-09-13 07:53:27,023 hkim-trainer INFO: Epoch[14] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:53:58,275 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:54:01,823 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:54:01,848 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:54:01,868 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.56 - validation evaluator metrics:\n",
            " \taccuracy: 0.7611\n",
            "\tce: 0.709891162109375\n",
            "2021-09-13 07:54:01,895 hkim-trainer INFO: Epoch[15] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:54:33,219 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:54:36,872 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:04\n",
            "2021-09-13 07:54:36,895 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:54:36,923 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.67 - validation evaluator metrics:\n",
            " \taccuracy: 0.7615\n",
            "\tce: 0.728841552734375\n",
            "2021-09-13 07:54:36,964 hkim-trainer INFO: Epoch[16] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:55:07,877 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:55:11,420 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:55:11,436 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:55:11,455 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.54 - validation evaluator metrics:\n",
            " \taccuracy: 0.77\n",
            "\tce: 0.6952634765625\n",
            "2021-09-13 07:55:11,467 hkim-trainer INFO: Epoch[17] Complete. Time taken: 00:00:34\n",
            "2021-09-13 07:55:42,406 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:55:45,999 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:55:46,014 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:55:46,037 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.61 - validation evaluator metrics:\n",
            " \taccuracy: 0.7725\n",
            "\tce: 0.685089990234375\n",
            "2021-09-13 07:55:46,057 hkim-trainer INFO: Epoch[18] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:56:17,155 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:56:20,766 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:56:20,774 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:56:20,785 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.59 - validation evaluator metrics:\n",
            " \taccuracy: 0.7778\n",
            "\tce: 0.66795830078125\n",
            "2021-09-13 07:56:20,794 hkim-trainer INFO: Epoch[19] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:56:52,105 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:56:55,631 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:56:55,655 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:56:55,670 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.53 - validation evaluator metrics:\n",
            " \taccuracy: 0.791\n",
            "\tce: 0.63057861328125\n",
            "2021-09-13 07:56:55,687 hkim-trainer INFO: Epoch[20] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:57:26,883 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:57:30,494 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:04\n",
            "2021-09-13 07:57:30,508 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:57:30,516 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.61 - validation evaluator metrics:\n",
            " \taccuracy: 0.7788\n",
            "\tce: 0.68194951171875\n",
            "2021-09-13 07:57:30,532 hkim-trainer INFO: Epoch[21] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:58:01,960 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:58:05,571 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:04\n",
            "2021-09-13 07:58:05,580 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:58:05,592 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.61 - validation evaluator metrics:\n",
            " \taccuracy: 0.7892\n",
            "\tce: 0.6449546875\n",
            "2021-09-13 07:58:05,603 hkim-trainer INFO: Epoch[22] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:58:37,039 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:58:40,568 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:58:40,590 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:58:40,607 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.53 - validation evaluator metrics:\n",
            " \taccuracy: 0.7823\n",
            "\tce: 0.665587109375\n",
            "2021-09-13 07:58:40,625 hkim-trainer INFO: Epoch[23] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:59:12,041 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:59:15,555 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:59:15,613 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:59:15,628 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.56 - validation evaluator metrics:\n",
            " \taccuracy: 0.7856\n",
            "\tce: 0.67493076171875\n",
            "2021-09-13 07:59:15,635 hkim-trainer INFO: Epoch[24] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:59:15,643 hkim-trainer INFO: Engine run complete. Time taken: 00:14:25\n",
            "2021-09-13 07:59:15,717 ignite.distributed.launcher.Parallel INFO: End of run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrhKjYC4mLaU"
      },
      "source": [
        " TPU 환경에서 8개의 프로세스를 생성해 실행시킨 결과 중 일부를 살펴보면 다음과 같다.\n",
        "\n",
        ">*2021-09-13 07:25:30,682 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'xla-tpu'*  \n",
        "*2021-09-13 07:25:30,685 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes:*  \n",
        "\t>>*nproc_per_node: 8*  \n",
        "\t*nnodes: 1*  \n",
        "\t*node_rank: 0** \n",
        "\t*start_method: fork**\n",
        "\n",
        ">*2021-09-13 07:25:30,689 ignite.distributed.launcher.Parallel INFO: Spawn function '<function training at 0x7f723ffcc950>' in 8 processes*\n",
        "...  \n",
        "*2021-09-13 07:28:01,663 hkim-trainer INFO: Epoch[1] Complete. Time taken: 00:01:04*  \n",
        "...  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbEe_icExtvE"
      },
      "source": [
        " 모델 학습을 위한  trainer에서 최초 epoch 실행 시 약 1분 4초의 시간이 소요되었음을 알 수 있다. 그리고 나머지 epoch 실행 결과는 아래와 같다. \n",
        "\n",
        "...  \n",
        ">*2021-09-13 07:28:42,355 hkim-trainer INFO: Epoch[2] Complete. Time taken: 00:00:41*  \n",
        "...  \n",
        ">*2021-09-13 07:29:25,320 hkim-trainer INFO: Epoch[3] Complete. Time taken: 00:00:43*  \n",
        "...  \n",
        "*2021-09-13 07:30:05,449 hkim-trainer INFO: Epoch[4] Complete. Time taken: 00:00:40*  \n",
        "...  \n",
        "*2021-09-13 07:30:46,015 hkim-trainer INFO: Epoch[5] Complete. Time taken: 00:00:41*  \n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Mbi8WhGxwaZ"
      },
      "source": [
        " 최초 1분 4초에서 점차 시간이 줄어들어 약 40~43초로 안정화되는데 이는 학습 시 캐시 히트율이 증가함에 따라 영향을 받는 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQL39wXmXx9k"
      },
      "source": [
        "## License\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXio6q3iX5Ig"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "Note: This is not an official [LG AI Research](https://www.lgresearch.ai/) product but sample code provided for an educational purpose\n",
        "\n",
        "<br/>\n",
        "author: John H. Kim\n",
        "<br/>  \n",
        "email: john.kim@lgresearch.ai / secutron@naver.com  \n",
        "\n",
        "\n",
        "---"
      ]
    }
  ]
}